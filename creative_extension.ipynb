{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Title hyperlinks\n",
    "title_links = pd.read_csv(\"Data/soc-redditHyperlinks-title.tsv\",'\\t')\n",
    "## Body hyperlinks\n",
    "body_links = pd.read_csv(\"Data/soc-redditHyperlinks-body.tsv\",'\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rddtgaming</td>\n",
       "      <td>rddtrust</td>\n",
       "      <td>1u4pzzs</td>\n",
       "      <td>2013-12-31 16:39:18</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0,23.0,0.76,0.0,0.44,0.12,0.12,4.0,4.0,0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xboxone</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1u4tmfs</td>\n",
       "      <td>2013-12-31 17:59:11</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ps4</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1u4tmos</td>\n",
       "      <td>2013-12-31 17:59:40</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>leangains</td>\n",
       "      <td>1u50xfs</td>\n",
       "      <td>2013-12-31 19:01:56</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0,43.0,0.775510204082,0.0,0.265306122449,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>lifeprotips</td>\n",
       "      <td>1u51nps</td>\n",
       "      <td>2013-12-31 21:02:28</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0,14.0,0.785714285714,0.0,0.428571428571,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "0         rddtgaming         rddtrust  1u4pzzs  2013-12-31 16:39:18   \n",
       "1            xboxone    battlefield_4  1u4tmfs  2013-12-31 17:59:11   \n",
       "2                ps4    battlefield_4  1u4tmos  2013-12-31 17:59:40   \n",
       "3  fitnesscirclejerk        leangains  1u50xfs  2013-12-31 19:01:56   \n",
       "4  fitnesscirclejerk      lifeprotips  1u51nps  2013-12-31 21:02:28   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \n",
       "0               1  25.0,23.0,0.76,0.0,0.44,0.12,0.12,4.0,4.0,0.0,...  \n",
       "1               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...  \n",
       "2               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...  \n",
       "3               1  49.0,43.0,0.775510204082,0.0,0.265306122449,0....  \n",
       "4               1  14.0,14.0,0.785714285714,0.0,0.428571428571,0....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>teamredditteams</td>\n",
       "      <td>1u4nrps</td>\n",
       "      <td>2013-12-31 16:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0,298.0,0.75652173913,0.0173913043478,0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>theredlion</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1u4qkd</td>\n",
       "      <td>2013-12-31 18:18:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>101.0,98.0,0.742574257426,0.019801980198,0.049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>inlandempire</td>\n",
       "      <td>bikela</td>\n",
       "      <td>1u4qlzs</td>\n",
       "      <td>2014-01-01 14:54:35</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0,85.0,0.752941176471,0.0235294117647,0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1u4sjvs</td>\n",
       "      <td>2013-12-31 17:37:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.0,949.0,0.772241992883,0.0017793594306,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>playmygame</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>1u4w5ss</td>\n",
       "      <td>2014-01-01 02:51:13</td>\n",
       "      <td>1</td>\n",
       "      <td>715.0,622.0,0.777622377622,0.00699300699301,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "0  leagueoflegends  teamredditteams  1u4nrps  2013-12-31 16:39:58   \n",
       "1       theredlion           soccer   1u4qkd  2013-12-31 18:18:37   \n",
       "2     inlandempire           bikela  1u4qlzs  2014-01-01 14:54:35   \n",
       "3              nfl              cfb  1u4sjvs  2013-12-31 17:37:55   \n",
       "4       playmygame          gamedev  1u4w5ss  2014-01-01 02:51:13   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \n",
       "0               1  345.0,298.0,0.75652173913,0.0173913043478,0.08...  \n",
       "1              -1  101.0,98.0,0.742574257426,0.019801980198,0.049...  \n",
       "2               1  85.0,85.0,0.752941176471,0.0235294117647,0.082...  \n",
       "3               1  1124.0,949.0,0.772241992883,0.0017793594306,0....  \n",
       "4               1  715.0,622.0,0.777622377622,0.00699300699301,0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the data is presented is as follows\n",
    "\n",
    "- SOURCE_SUBREDDIT: the subreddit where the link originates\n",
    "- TARGET_SUBREDDIT: the subreddit where the link ends\n",
    "- POST_ID: the post in the source subreddit that starts the link\n",
    "- TIMESTAMP: time time of the post\n",
    "- POST_LABEL: label indicating if the source post is explicitly negative towards the target post. The value is -1 if the source is negative towards the target, and 1 if it is neutral or positive. The label is created using crowd-sourcing and training a text based classifier, and is better than simple sentiment analysis of the posts. Please see the reference paper for details.\n",
    "- POST_PROPERTIES: a vector representing the text properties of the source post, listed as a list of comma separated numbers. The vector elements are the following:\n",
    "    1. Number of characters\n",
    "    2. Number of characters without counting white space\n",
    "    3. Fraction of alphabetical characters\n",
    "    4. Fraction of digits\n",
    "    5. Fraction of uppercase characters\n",
    "    6. Fraction of white spaces\n",
    "    7. Fraction of special characters, such as comma, exclamation mark, etc.\n",
    "    8. Number of words\n",
    "    9. Number of unique works\n",
    "    10. Number of long words (at least 6 characters)\n",
    "    11. Average word length\n",
    "    12. Number of unique stopwords\n",
    "    13. Fraction of stopwords\n",
    "    14. Number of sentences\n",
    "    15. Number of long sentences (at least 10 words)\n",
    "    16. Average number of characters per sentence\n",
    "    17. Average number of words per sentence\n",
    "    18. Automated readability index\n",
    "    19. Positive sentiment calculated by VADER\n",
    "    20. Negative sentiment calculated by VADER\n",
    "    21. Compound sentiment calculated by VADER\n",
    "    22. LIWC_Funct\n",
    "    23. LIWC_Pronoun\n",
    "    24. LIWC_Ppron\n",
    "    25. LIWC_I\n",
    "    26. LIWC_We\n",
    "    27. LIWC_You\n",
    "    28. LIWC_SheHe\n",
    "    29. LIWC_They\n",
    "    30. LIWC_Ipron\n",
    "    31. LIWC_Article\n",
    "    32. LIWC_Verbs\n",
    "    33. LIWC_AuxVb\n",
    "    34. LIWC_Past\n",
    "    35. LIWC_Present\n",
    "    36. LIWC_Future\n",
    "    37. LIWC_Adverbs\n",
    "    38. LIWC_Prep\n",
    "    39. LIWC_Conj\n",
    "    40. LIWC_Negate\n",
    "    41. LIWC_Quant\n",
    "    42. LIWC_Numbers\n",
    "    43. LIWC_Swear\n",
    "    44. LIWC_Social\n",
    "    45. LIWC_Family\n",
    "    46. LIWC_Friends\n",
    "    47. LIWC_Humans\n",
    "    48. LIWC_Affect\n",
    "    49. LIWC_Posemo\n",
    "    50. LIWC_Negemo\n",
    "    51. LIWC_Anx\n",
    "    52. LIWC_Anger\n",
    "    53. LIWC_Sad\n",
    "    54. LIWC_CogMech\n",
    "    55. LIWC_Insight\n",
    "    56. LIWC_Cause\n",
    "    57. LIWC_Discrep\n",
    "    58. LIWC_Tentat\n",
    "    59. LIWC_Certain\n",
    "    60. LIWC_Inhib\n",
    "    61. LIWC_Incl\n",
    "    62. LIWC_Excl\n",
    "    63. LIWC_Percept\n",
    "    64. LIWC_See\n",
    "    65. LIWC_Hear\n",
    "    66. LIWC_Feel\n",
    "    67. LIWC_Bio\n",
    "    68. LIWC_Body\n",
    "    69. LIWC_Health\n",
    "    70. LIWC_Sexual\n",
    "    71. LIWC_Ingest\n",
    "    72. LIWC_Relativ\n",
    "    73. LIWC_Motion\n",
    "    74. LIWC_Space\n",
    "    75. LIWC_Time\n",
    "    76. LIWC_Work\n",
    "    77. LIWC_Achiev\n",
    "    78. LIWC_Leisure\n",
    "    79. LIWC_Home\n",
    "    80. LIWC_Money\n",
    "    81. LIWC_Relig\n",
    "    82. LIWC_Death\n",
    "    83. LIWC_Assent\n",
    "    84. LIWC_Dissent\n",
    "    85. LIWC_Nonflu\n",
    "    86. LIWC_Filler    \n",
    "\n",
    "###  Note that POST_PROPERTIES were constructed in order to assign a sign (-1 or 1) to the directed link betweet the SOURCE_SUBREDDIT and TARGET_SUBREDDIT.\n",
    "### These signs are contained in POST_LABEL. Thus, we will basically need only those three features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Title links :\n",
      "The number of links in the title links dataset:\t 571927\n",
      "The number of unique source subreddits: \t 43695\n",
      "the set of all subreddits in the title dataset:\t 54075\n",
      "====================\n",
      "====================\n",
      "Body links :\n",
      "The number of links in the body links dataset: \t 286561\n",
      "The number of unique source subreddits : \t 27863\n",
      "the set of all subreddits in the body dataset :\t 35776\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "## Drop unwanted features \n",
    "title_links = title_links[[\"SOURCE_SUBREDDIT\",\"TARGET_SUBREDDIT\",\"LINK_SENTIMENT\"]]\n",
    "body_links = body_links[[\"SOURCE_SUBREDDIT\",\"TARGET_SUBREDDIT\",\"LINK_SENTIMENT\"]]\n",
    "\n",
    "## Print some characteristics for Title links\n",
    "print(20*'=')\n",
    "print('Title links :')\n",
    "title_source_subreddits = title_links.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in the title links dataset:\\t {len(title_source_subreddits)}')\n",
    "title_source_set = set(title_source_subreddits)\n",
    "print(f'The number of unique source subreddits: \\t {len(title_source_set)}')\n",
    "title_subreddits = set(title_links.SOURCE_SUBREDDIT.values.tolist() + title_links.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits in the title dataset:\\t {len(title_subreddits)}')\n",
    "print(20*'=')\n",
    "\n",
    "## Print some characteristics for Body links\n",
    "print(20*'=')\n",
    "print(\"Body links :\")\n",
    "body_source_subreddits = body_links.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in the body links dataset: \\t {len(body_source_subreddits)}')\n",
    "body_source_set = set(body_source_subreddits)\n",
    "print(f'The number of unique source subreddits : \\t {len(body_source_set)}')\n",
    "body_subreddits = set(body_links.SOURCE_SUBREDDIT.values.tolist() + body_links.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits in the body dataset :\\t {len(body_subreddits)}')\n",
    "print(20*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subreddit links :\n",
      "The number of links in all data: \t 858488\n",
      "The number of unique source subreddits:  55863\n",
      "the set of all subreddits :\t\t 67180\n"
     ]
    }
   ],
   "source": [
    "## Here we concatenate the both dataframes to create a unique dataset of connexions between subreddits.\n",
    "Data = pd.concat([title_links,body_links])\n",
    "\n",
    "print(\"All subreddit links :\")\n",
    "source_subreddits = Data.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in all data: \\t {len(source_subreddits)}')\n",
    "source_set = set(source_subreddits)\n",
    "print(f'The number of unique source subreddits:  {len(source_set)}')\n",
    "subreddits = set(Data.SOURCE_SUBREDDIT.values.tolist() + Data.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits :\\t\\t {len(subreddits)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 776278 positive links and 82210 negative links\n",
      "REDDIT : Pourcentage of (+)edges is 90.4% and pourcentage of (-)edges is 9.6%\n"
     ]
    }
   ],
   "source": [
    "## Let's see the number and pourcentages of positive and negatives links\n",
    "number_pos_links = Data.where(Data.LINK_SENTIMENT==1).count()[0]\n",
    "number_neg_links = Data.where(Data.LINK_SENTIMENT==-1).count()[0]\n",
    "print(f'There is {number_pos_links} positive links and {number_neg_links} negative links')\n",
    "\n",
    "print(f'REDDIT : Pourcentage of (+)edges is {round(number_pos_links*100/len(Data),1)}% and pourcentage of (-)edges is {round(number_neg_links*100/len(Data),1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing these pourcentages to the ones of Epinions or Slashdot datasets, We can see that Reddit has a lot less negatives links than the others. We can state (hypothetize ?) that the interactions betweet subreddits are mostly positive and that negative links are especially for conflicts rather than just negative opinion/vote and of course, conflicts are much less likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a graph of subreddits links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDDIT:    Nodes = 67180  Edges = 339643\n",
      "REDDIT : Pourcentage of (+)edges is 92.5% and pourcentage of (-)edges is 7.5%\n"
     ]
    }
   ],
   "source": [
    "complete_graph = nx.from_pandas_edgelist(Data,source='SOURCE_SUBREDDIT', target=\"TARGET_SUBREDDIT\", edge_attr = \"LINK_SENTIMENT\",create_using=nx.DiGraph)\n",
    "\n",
    "nbr_nodes = complete_graph.number_of_nodes()\n",
    "nbr_edges = complete_graph.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes,\" Edges =\",nbr_edges)\n",
    "\n",
    "sum_of_pos = sum(1 if w[\"LINK_SENTIMENT\"]==1 else 0 for (_,_,w) in complete_graph.edges(data=True))\n",
    "sum_of_neg = sum(1 if w[\"LINK_SENTIMENT\"]==-1 else 0 for (_,_,w) in complete_graph.edges(data=True))\n",
    "pourc_of_pos = round(100 *sum_of_pos/nbr_edges,1)\n",
    "pourc_of_neg = round(100 *sum_of_neg/nbr_edges,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos, neg= pourc_of_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this way of creating the graph led us to dropping an huge number of edges (from 858488 to 339643) while keeping the same number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since our dataset contains a lot of duplicates edges (Some of those edges may be all positive or all negative or a combination of positive and negative signs). Creating our directed graph directly from those edges, will ommit these duplicates and will take into account only their last occurences. Thus , it will take only the last sign of the link betweet those two subreddits. This will alter our perspectives since in a case where all links but the LAST ONE , between subreddit A and subreddit B were negative, this generated graph will take only the positive link and we will be dropping very important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and generate a multiple directed graph (MultiDiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDDIT:    Nodes = 67180  Edges = 858488\n",
      "REDDIT : Pourcentage of (+)edges is 90.4% and pourcentage of (-)edges is 9.6%\n"
     ]
    }
   ],
   "source": [
    "complete_multi_graph = nx.from_pandas_edgelist(Data,source='SOURCE_SUBREDDIT', target=\"TARGET_SUBREDDIT\", edge_attr = \"LINK_SENTIMENT\",create_using=nx.MultiDiGraph)\n",
    "\n",
    "nbr_nodes = complete_multi_graph.number_of_nodes()\n",
    "nbr_edges = complete_multi_graph.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes,\" Edges =\",nbr_edges)\n",
    "\n",
    "sum_of_pos = sum(1 if w[\"LINK_SENTIMENT\"]==1 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "sum_of_neg = sum(1 if w[\"LINK_SENTIMENT\"]==-1 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "pourc_of_pos = round(100 *sum_of_pos/nbr_edges,1)\n",
    "pourc_of_neg = round(100 *sum_of_neg/nbr_edges,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos, neg= pourc_of_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see now that this graph contains more informations about the data than the other one; It complete and have all edges and nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since one of our objectives is to compare the similarities and differences between the individuals datasets (Epinions, slashdot and wikipedia) and the communities dataset (Reddit) , apart from this methode of creating a multiple edges directed graph, we decides to generate another graph that , for each multiple signed edges between same two nodes, will create a single edge with the mean of all those signs as unique weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we group by (source,target) but instead of keeping all weights, we sum them into one weight\n",
    "groupedBySource_Target_mean = Data.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT']).LINK_SENTIMENT.apply(lambda x: np.mean(x)).to_frame()\n",
    "## The groupby function makes the pair (source,target) as index.\n",
    "# To construct the graph, we need to have list of all sources , targets and signs in a dataframe \n",
    "listed_source = [ elem[0] for elem in groupedBySource_Target_mean.index]\n",
    "listed_target = [ elem[1] for elem in groupedBySource_Target_mean.index]\n",
    "listed_sign = [ elem[0] for elem in groupedBySource_Target_mean.values ]\n",
    "\n",
    "data_mean = pd.DataFrame({\"source\":listed_source,\"target\":listed_target,\"sign\":listed_sign})\n",
    "\n",
    "graph_mean = nx.from_pandas_edgelist(data_mean,source='source', target=\"target\", edge_attr = \"sign\",create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This meaned graph contains 339643 signed edges.\n",
      "The number of edges which mean is equal to 1 is 298473\n",
      "The number of edges which mean is equal to -1 is 18104\n"
     ]
    }
   ],
   "source": [
    "print(f'This meaned graph contains {len(data_mean)} signed edges.')\n",
    "print(f'The number of edges which mean is equal to 1 is {len(data_mean[data_mean.sign==1])}')\n",
    "print(f'The number of edges which mean is equal to -1 is {len(data_mean[data_mean.sign==-1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the mean sign of the edges by majority 1 or -1. \n",
    "### From this, we decided to define \"FRIENDS Communities\" by the communities which only have **multiple** positive edges. and \"ENEMIES communities\" by the communities which only have multiple negative edges.\n",
    "\n",
    "for this, we need to isolate the communities that have multiple edges between them : ie: we can't consider that two communities are enemies just by having only one negative link between them. so we just keep multiple linked communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We groupby the data using pairs (source,target) and collect all link signs between same pair in one attribute (a dictionary)\n",
    "groupedBySource_Target_pair = Data.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT']).LINK_SENTIMENT.apply(lambda x: list(x)).to_frame()\n",
    "groupedBySource_Target_pair.LINK_SENTIMENT = groupedBySource_Target_pair.LINK_SENTIMENT.apply(lambda x: dict(zip(np.arange(len(x)), x)))\n",
    "## The groupby function makes the pair (source,target) as index.\n",
    "# To construct the graph, we need to have list of all sources , targets and signs in a dataframe \n",
    "listed_source_dict = [ elem[0] for elem in groupedBySource_Target_pair.index]\n",
    "listed_target_dict = [ elem[1] for elem in groupedBySource_Target_pair.index]\n",
    "listed_sign_dict = [ elem[0] for elem in groupedBySource_Target_pair.values ]\n",
    "\n",
    "data_dict_df = pd.DataFrame({\"source\":listed_source_dict,\"target\":listed_target_dict,\"sign\":listed_sign_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices =[]\n",
    "for i,elem in zip(range(len(data_dict_df.sign.values)),data_dict_df.sign.values):\n",
    "    if len(elem)>=2: indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiple_edges = data_dict_df.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>07scape</td>\n",
       "      <td>osrstranscripts</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0magick</td>\n",
       "      <td>occult</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0x02</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0x10c</td>\n",
       "      <td>techcompliant</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100daysofketo</td>\n",
       "      <td>keto</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339622</td>\n",
       "      <td>zurich</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339629</td>\n",
       "      <td>zxspectrum</td>\n",
       "      <td>retrogaming</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339634</td>\n",
       "      <td>zylooxwrites</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339635</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339637</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>summonerschool</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source           target  \\\n",
       "1             07scape  osrstranscripts   \n",
       "6             0magick           occult   \n",
       "10               0x02   writingprompts   \n",
       "12              0x10c    techcompliant   \n",
       "22      100daysofketo             keto   \n",
       "...               ...              ...   \n",
       "339622         zurich      switzerland   \n",
       "339629     zxspectrum      retrogaming   \n",
       "339634   zylooxwrites   writingprompts   \n",
       "339635      zyramains  leagueoflegends   \n",
       "339637      zyramains   summonerschool   \n",
       "\n",
       "                                                     sign  \n",
       "1                                            {0: 1, 1: 1}  \n",
       "6                                            {0: 1, 1: 1}  \n",
       "10                                           {0: 1, 1: 1}  \n",
       "12                                           {0: 1, 1: 1}  \n",
       "22                         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}  \n",
       "...                                                   ...  \n",
       "339622                                       {0: 1, 1: 1}  \n",
       "339629                                       {0: 1, 1: 1}  \n",
       "339634                           {0: 1, 1: 1, 2: 1, 3: 1}  \n",
       "339635  {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...  \n",
       "339637         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}  \n",
       "\n",
       "[93916 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_multiple_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_edges_meaned_data = data_mean.loc[indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1624</td>\n",
       "      <td>5555555</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1986</td>\n",
       "      <td>9gag</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2615</td>\n",
       "      <td>abuseinterrupted</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2689</td>\n",
       "      <td>abuseinterrupted</td>\n",
       "      <td>theredpill</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2696</td>\n",
       "      <td>abuseinterrupted</td>\n",
       "      <td>upliftingnews</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335653</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>savedyouaclick</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336280</td>\n",
       "      <td>wtfdidijustread</td>\n",
       "      <td>mensrights</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337522</td>\n",
       "      <td>yankees</td>\n",
       "      <td>nfl</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337825</td>\n",
       "      <td>yishansucks</td>\n",
       "      <td>iama</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339463</td>\n",
       "      <td>zombies</td>\n",
       "      <td>doesanybodyelse</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source               target  sign\n",
       "1624             5555555  relationship_advice  -1.0\n",
       "1986                9gag            askreddit  -1.0\n",
       "2615    abuseinterrupted         changemyview  -1.0\n",
       "2689    abuseinterrupted           theredpill  -1.0\n",
       "2696    abuseinterrupted        upliftingnews  -1.0\n",
       "...                  ...                  ...   ...\n",
       "335653    writingprompts       savedyouaclick  -1.0\n",
       "336280   wtfdidijustread           mensrights  -1.0\n",
       "337522           yankees                  nfl  -1.0\n",
       "337825       yishansucks                 iama  -1.0\n",
       "339463           zombies      doesanybodyelse  -1.0\n",
       "\n",
       "[778 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_edges_meaned_data[multiple_edges_meaned_data.sign==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_wanted_triads(graph):\n",
    "    triads = nx.triadic_census(graph)\n",
    "    total_triads = triads['030T']+triads['030C']\n",
    "    total_triads= total_triads+(2*(triads['120U']+triads['120D']+triads['120C']))\n",
    "    total_triads=total_triads+(4*triads['210'])+(8*triads['300'])\n",
    "    return total_triads\n",
    "\n",
    "total_triads = compute_count_wanted_triads(complete_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function used to parse wikipedia data\n",
    "\n",
    "def custom_parsing(path):\n",
    "    ## Initializing everything before parsing\n",
    "    \n",
    "    result_list = []\n",
    "\n",
    "    to_node = None\n",
    "    from_node = None\n",
    "    sign = None\n",
    "\n",
    "    ## Opening the file\n",
    "    ## Chose encoding=\"iso8859_16\" as simple \"UTF-8\" gave me errors\n",
    "    with open(path, 'r', encoding=\"iso8859_16\") as f:\n",
    "        \n",
    "        ## For each line ... \n",
    "        for line in f:\n",
    "            ## Split the line by \" \"\n",
    "            splitted = line.split()\n",
    "\n",
    "            ## If empty line, continue\n",
    "            if(len(splitted) == 0):\n",
    "                continue\n",
    "\n",
    "            ## If this is a \"U\" line ...\n",
    "            elif(splitted[0] == 'U'):\n",
    "                ## Take the id of the nominated user\n",
    "                to_node = int(splitted[1])\n",
    "\n",
    "            ## If this is a \"V\" line ...\n",
    "            elif(splitted[0] == 'V'):\n",
    "                ## Take the sign of the vote\n",
    "                sign = int(splitted[1])\n",
    "                \n",
    "                ## Take the id of voter\n",
    "                from_node = int(splitted[2])\n",
    "                \n",
    "                ## If the vote was neutral, don't take it (continue)\n",
    "                ## Else store the line in the intermediary list\n",
    "                if(sign == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    result_list.append([from_node, to_node, sign])\n",
    "            \n",
    "            ## If this is any other kind of line, continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    ## Converting the intermediary list into a dataframe and name columns correctly\n",
    "    result_df = pd.DataFrame(result_list, columns=['FromNodeId', 'ToNodeId', 'Sign'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data and sorting\n",
    "\n",
    "epinions_df = pd.read_csv(\"data/soc-sign-epinions.txt\", sep=\"\\t\", header=None, \n",
    "                          comment=\"#\", names=['FromNodeId', 'ToNodeId', 'Sign'])\n",
    "epinions_df = epinions_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)\n",
    "\n",
    "slashdot_df = pd.read_csv(\"data/soc-sign-Slashdot090221.txt\", sep=\"\\t\", header=None, \n",
    "                          comment=\"#\", names=['FromNodeId', 'ToNodeId', 'Sign'])\n",
    "slashdot_df = slashdot_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)\n",
    "\n",
    "wikipedia_df = custom_parsing(\"data/wikiElec.ElecBs3.txt\")\n",
    "wikipedia_df = wikipedia_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_graph = nx.from_pandas_edgelist(epinions_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                         edge_attr=\"Sign\", create_using=nx.DiGraph)\n",
    "\n",
    "slashdot_graph = nx.from_pandas_edgelist(slashdot_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                         edge_attr=\"Sign\", create_using=nx.DiGraph)\n",
    "\n",
    "wikipedia_graph = nx.from_pandas_edgelist(wikipedia_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                          edge_attr=\"Sign\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_links_names = [f't{i}' for i in range(1, 17)]\n",
    "    \n",
    "census = pd.DataFrame(0, index = pd.Index(c_links_names), columns = ['+', '-']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     +  -\n",
       "t1   0  0\n",
       "t2   0  0\n",
       "t3   0  0\n",
       "t4   0  0\n",
       "t5   0  0\n",
       "t6   0  0\n",
       "t7   0  0\n",
       "t8   0  0\n",
       "t9   0  0\n",
       "t10  0  0\n",
       "t11  0  0\n",
       "t12  0  0\n",
       "t13  0  0\n",
       "t14  0  0\n",
       "t15  0  0\n",
       "t16  0  0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANT_TRIADS = ['030T', '120U', '120C', '210', '300']\n",
    "\n",
    "C_LINKS_TYPES = {\n",
    "    tuple(sorted([('vw', 1), ('wu', 1)])) : 't1',\n",
    "    tuple(sorted([('vw', 1), ('wu', -1)])) : 't2',\n",
    "    tuple(sorted([('vw', 1), ('uw', 1)])) : 't3',\n",
    "    tuple(sorted([('vw', 1), ('uw', -1)])) : 't4',\n",
    "    tuple(sorted([('vw', -1), ('wu', 1)])) : 't5',\n",
    "    tuple(sorted([('vw', -1), ('wu', -1)])) : 't6',\n",
    "    tuple(sorted([('vw', -1), ('uw', 1)])) : 't7',\n",
    "    tuple(sorted([('vw', -1), ('uw', -1)])) : 't8', \n",
    "    tuple(sorted([('wv', 1), ('wu', 1)])) : 't9',\n",
    "    tuple(sorted([('wv', 1), ('wu', -1)])) : 't10',\n",
    "    tuple(sorted([('wv', 1), ('uw', 1)])) : 't11',\n",
    "    tuple(sorted([('wv', 1), ('uw', -1)])) : 't12',\n",
    "    tuple(sorted([('wv', -1), ('wu', 1)])) : 't13',\n",
    "    tuple(sorted([('wv', -1), ('wu', -1)])) : 't14',\n",
    "    tuple(sorted([('wv', -1), ('uw', 1)])) : 't15',\n",
    "    tuple(sorted([('wv', -1), ('uw', -1)])) : 't16',\n",
    "}\n",
    "\n",
    "\n",
    "def compute_c_link_types(graph, v, u, w): \n",
    "    edge_dist = {\n",
    "        'vw': w in graph[v],\n",
    "        'wv': v in graph[w],\n",
    "        'uw': w in graph[u],\n",
    "        'wu': u in graph[w]\n",
    "    }\n",
    "    \n",
    "    duplicates = []\n",
    "    non_duplicates = []\n",
    "    \n",
    "    ## If an edge v->w exists in the graph ...\n",
    "    if(edge_dist['vw']):\n",
    "        ## AND an edge w->v exists in the graph ...\n",
    "        if(edge_dist['wv']):\n",
    "            ## (the edges formed by the pair (v, w) are stored in the \"duplicates\" list)\n",
    "            duplicates.append([(v, w, 'vw'), (w, v, 'wv')])\n",
    "        else:\n",
    "            ## Only the edge v->w exists, store it in the \"non_duplicates\" list\n",
    "            non_duplicates.append((v, w, 'vw'))\n",
    "    else:\n",
    "        ## Only the w->v exists, store it in the \"non_duplicates\" list\n",
    "        non_duplicates.append((w, v, 'wv'))\n",
    "\n",
    "    ## If an edge u->w exists in the graph ...\n",
    "    if(edge_dist['uw']):\n",
    "        ## AND an edge w->u exists in the graph ...\n",
    "        if(edge_dist['wu']):\n",
    "            ## (the edges formed by the pair (u, w) are stored in the \"duplicates\" list)\n",
    "            duplicates.append([(u, w, 'uw'), (w, u, 'wu')])\n",
    "        else:\n",
    "            ## Only the edge u->w exists, store it in the \"non_duplicates\" list\n",
    "            non_duplicates.append((u, w, 'uw'))\n",
    "    else:\n",
    "        ## Only the w->u exists, store it in the \"non_duplicates\" list\n",
    "        non_duplicates.append((w, u, 'wu'))\n",
    "    \n",
    "    dup_len = len(duplicates)\n",
    "    non_dup_len = len(non_duplicates)\n",
    "\n",
    "    ## Computing the different combination possible from the duplicates list\n",
    "    ## If only one pair was added to the duplicates list, there would be 2 combinations\n",
    "    ## If two pairs were added to the duplicates list, there would be 4 combinations\n",
    "    ## If three pairs were added to the duplicates list, there would be 8 combinations\n",
    "    duplicates_combs = itertools.product(*duplicates)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ## combi is of the form []\n",
    "    for combi in duplicates_combs:\n",
    "        c_link_index = []\n",
    "        \n",
    "        for i in range(dup_len):\n",
    "            edge_direction = combi[i][2]\n",
    "            edge_sign = graph[combi[i][0]][combi[i][1]]['Sign']\n",
    "            c_link_index.append((edge_direction, edge_sign))\n",
    "            \n",
    "        for i in range(non_dup_len):\n",
    "            edge_direction = non_duplicates[i][2]\n",
    "            edge_sign = graph[non_duplicates[i][0]][non_duplicates[i][1]]['Sign']\n",
    "            c_link_index.append((edge_direction, edge_sign))\n",
    "        \n",
    "        c_link_type = C_LINKS_TYPES[tuple(sorted(c_link_index))]\n",
    "        \n",
    "        result.append(c_link_type)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def c_links_census(graph):\n",
    "    # Initialize the count for each triad to be zero.\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    t3 = 0\n",
    "    t4 = 0\n",
    "    t5 = 0\n",
    "    t6 = 0\n",
    "    t7 = 0\n",
    "    t8 = 0\n",
    "    t9 = 0\n",
    "    t10 = 0\n",
    "    t11 = 0\n",
    "    t12 = 0\n",
    "    t13 = 0\n",
    "    t14 = 0\n",
    "    t15 = 0\n",
    "    t16 = 0\n",
    "    \n",
    "    census = {\n",
    "        f't{i}': {\n",
    "            '+': 0,\n",
    "            '-': 0\n",
    "    } for i in range(1, 17)}\n",
    "    \n",
    "    census_edges = {\n",
    "        f't{i}' : set() for i in range(1, 17)\n",
    "    }\n",
    "    \n",
    "    c_links_names = [f't{i}' for i in range(1, 17)]\n",
    "    \n",
    "    census = pd.DataFrame(0, index = pd.Index(c_links_names), columns = ['+', '-']) \n",
    "    \n",
    "    n = len(graph)\n",
    "    \n",
    "    m = {v: i for i, v in enumerate(graph)}\n",
    "    \n",
    "    for v in graph:\n",
    "        vnbrs = set(graph.succ[v])\n",
    "        \n",
    "        for u in vnbrs:\n",
    "            if m[u] <= m[v]:\n",
    "                continue\n",
    "\n",
    "            neighbors_old = (vnbrs | set(graph.pred[v]) | set(graph.succ[u]) | set(graph.pred[u])) - {u, v}\n",
    "\n",
    "            neighbors1 = (set(graph.pred[v]) & set(graph.pred[u]))\n",
    "            neighbors2 = (set(graph.pred[v]) & set(graph.succ[u]))\n",
    "            neighbors3 = (vnbrs & set(graph.pred[u]))\n",
    "            neighbors4 = (vnbrs & set(graph.succ[u])) \n",
    "            \n",
    "            #neighbors = (neighbors1 | neighbors2 | neighbors3 | neighbors4) - {u, v}\n",
    "            \n",
    "#             printable = ''\n",
    "            \n",
    "#             if(len(list(neighbors_old)) < len(list(neighbors))):\n",
    "#                 printable = 'TAHCHELEK !'\n",
    "#             else:\n",
    "#                 printable = 'BON BON BON !'\n",
    "            \n",
    "#             print(f'old : {len(list(neighbors_old))} / new : {len(list(neighbors))} ! {printable}')\n",
    "            \n",
    "            for w in neighbors1:\n",
    "                ## Here triads are : v <--x--> u (either t9 or t10 , or t13 or t14)\n",
    "                sign_xv= '-' if graph[x][v]['sign']==-1 else '+'\n",
    "                sign_xu= '-' if graph[x][u]['sign']==-1 else '+'\n",
    "                typ = sign_xv+sign_xu\n",
    "                if typ=='++': t9 +=1\n",
    "                elif typ=='+-': t10+=1\n",
    "                elif typ=='-+':t13+=1\n",
    "                else : t14+=1\n",
    "                \n",
    "            for w in neighbors2:\n",
    "                ## Here triads are : v--> u --> x --> v (either t11 or t12 , or t15 or t16)\n",
    "                sign_xv= '-' if graph[x][v]['sign']==-1 else '+'\n",
    "                sign_ux= '-' if graph[u][x]['sign']==-1 else '+'\n",
    "                typ = sign_xv+sign_ux\n",
    "                if typ=='++': t11 +=1\n",
    "                elif typ=='+-': t12+=1\n",
    "                elif typ=='-+':t15+=1\n",
    "                else : t16+=1\n",
    "                \n",
    "                \n",
    "            for w in neighbors3:\n",
    "                ## Here triads are : v--> x --> u (either t11 or t12 , or t15 or t13)\n",
    "                sign_vx= '-' if graph[v][x]['sign']==-1 else '+'\n",
    "                sign_xu= '-' if graph[x][u]['sign']==-1 else '+'\n",
    "                typ = sign_vx+sign_xu\n",
    "                if typ=='++': t1 +=1\n",
    "                elif typ=='+-': t2+=1\n",
    "                elif typ=='-+':t5+=1\n",
    "                else : t6+=1\n",
    "                    \n",
    "            \n",
    "            for w in neighbors4:\n",
    "                ## Here triads are : v--> x <-- u (either t3 or t4 , or t7 or t8)\n",
    "                sign_vx= '-' if graph[v][x]['sign']==-1 else '+'\n",
    "                sign_ux= '-' if graph[u][x]['sign']==-1 else '+'\n",
    "                typ = sign_vx+sign_ux\n",
    "                if typ=='++': t3 +=1\n",
    "                elif typ=='+-': t4+=1\n",
    "                elif typ=='-+':t7+=1\n",
    "                else : t8+=1\n",
    "                    \n",
    "                    \n",
    "    return [t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11,t12,t13,t14,t15,t16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epin_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-566acfec53e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlisted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_links_census\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepin_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'epin_graph' is not defined"
     ]
    }
   ],
   "source": [
    "listed = c_links_census(epin_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_link_census_epinions, edges_per_c_link = c_links_census(epinions_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1308071</td>\n",
       "      <td>18558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>26717</td>\n",
       "      <td>31654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>1302381</td>\n",
       "      <td>25752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>33647</td>\n",
       "      <td>5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>49359</td>\n",
       "      <td>82704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6</th>\n",
       "      <td>7582</td>\n",
       "      <td>13710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t7</th>\n",
       "      <td>21420</td>\n",
       "      <td>67587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t8</th>\n",
       "      <td>63042</td>\n",
       "      <td>21874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t9</th>\n",
       "      <td>1879820</td>\n",
       "      <td>94867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>22217</td>\n",
       "      <td>45328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11</th>\n",
       "      <td>1012865</td>\n",
       "      <td>52312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t12</th>\n",
       "      <td>52395</td>\n",
       "      <td>12275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t13</th>\n",
       "      <td>28600</td>\n",
       "      <td>12294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t14</th>\n",
       "      <td>36737</td>\n",
       "      <td>12455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t15</th>\n",
       "      <td>25720</td>\n",
       "      <td>12664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t16</th>\n",
       "      <td>8837</td>\n",
       "      <td>2852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           +      -\n",
       "t1   1308071  18558\n",
       "t2     26717  31654\n",
       "t3   1302381  25752\n",
       "t4     33647   5131\n",
       "t5     49359  82704\n",
       "t6      7582  13710\n",
       "t7     21420  67587\n",
       "t8     63042  21874\n",
       "t9   1879820  94867\n",
       "t10    22217  45328\n",
       "t11  1012865  52312\n",
       "t12    52395  12275\n",
       "t13    28600  12294\n",
       "t14    36737  12455\n",
       "t15    25720  12664\n",
       "t16     8837   2852"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_link_census_epinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "t1\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t2\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t3\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t4\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t5\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t6\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t7\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t8\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t9\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t10\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t11\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t12\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t13\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t14\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t15\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t16\n",
      "Beginning generative baseline ...\n",
      "Generative baselines finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def compute_baseline(graph, list_of_c_links, gen_or_rec):\n",
    "    \n",
    "    if(gen_or_rec != 'generative' and gen_or_rec != 'receptive'):\n",
    "        raise ValueError('Impossible value for gen_or_rec argument !')\n",
    "    \n",
    "    sum_of_baselines = 0\n",
    "    \n",
    "    for c_link in list_of_c_links:\n",
    "        \n",
    "        if(gen_or_rec == 'generative'):\n",
    "            v = c_link[0]\n",
    "            succ = graph.succ[v]\n",
    "\n",
    "            list_of_edges = [(v, successor) for successor in succ]\n",
    "            list_of_positive_edges = [\n",
    "                (v, successor) for successor in succ if graph[v][successor]['Sign'] == 1\n",
    "            ]\n",
    "        else:\n",
    "            u = c_link[1]\n",
    "            pred = graph.pred[u]\n",
    "            \n",
    "            list_of_edges = [(predecessor, u) for predecessor in pred]\n",
    "            list_of_positive_edges = [\n",
    "                (predecessor, u) for predecessor in pred if graph[predecessor][u]['Sign'] == 1\n",
    "            ]\n",
    "        \n",
    "        total_edges = len(list_of_edges)\n",
    "        total_positive_edges = len(list_of_positive_edges)\n",
    "        \n",
    "        sum_of_baselines += total_positive_edges/total_edges\n",
    "        \n",
    "    return sum_of_baselines\n",
    "\n",
    "c_links_names = [key for key in edges_per_c_link.keys()]\n",
    "baselines = pd.DataFrame(index = pd.Index(c_links_names), columns = ['generative', 'receptive']) \n",
    "\n",
    "# baselines = {\n",
    "#     key : {\n",
    "#         'generative' : 0,\n",
    "#         'receptive' : 0\n",
    "#     } for key in edges_per_c_link.keys()\n",
    "# }\n",
    "\n",
    "for c_link_type in edges_per_c_link.keys():    \n",
    "    list_of_c_links = list(edges_per_c_link[c_link_type])\n",
    "    \n",
    "    print(80 * '=')\n",
    "    print(c_link_type)\n",
    "    print('Beginning generative baseline ...')\n",
    "    \n",
    "    baselines.loc[c_link_type]['generative'] = compute_baseline(epinions_graph, list_of_c_links, 'generative')\n",
    "    \n",
    "    print('Generative baselines finished !')\n",
    "    print('Beginning receptive baseline ...')\n",
    "    \n",
    "    baselines.loc[c_link_type]['receptive'] = compute_baseline(epinions_graph, list_of_c_links, 'receptive')\n",
    "    \n",
    "    print('Receptive baseline finished !')\n",
    "    print(80 * '=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = baselines.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1308071</td>\n",
       "      <td>18558</td>\n",
       "      <td>1326629</td>\n",
       "      <td>0.986011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>26717</td>\n",
       "      <td>31654</td>\n",
       "      <td>58371</td>\n",
       "      <td>0.457710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>1302381</td>\n",
       "      <td>25752</td>\n",
       "      <td>1328133</td>\n",
       "      <td>0.980610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>33647</td>\n",
       "      <td>5131</td>\n",
       "      <td>38778</td>\n",
       "      <td>0.867683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>49359</td>\n",
       "      <td>82704</td>\n",
       "      <td>132063</td>\n",
       "      <td>0.373753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6</th>\n",
       "      <td>7582</td>\n",
       "      <td>13710</td>\n",
       "      <td>21292</td>\n",
       "      <td>0.356096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t7</th>\n",
       "      <td>21420</td>\n",
       "      <td>67587</td>\n",
       "      <td>89007</td>\n",
       "      <td>0.240655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t8</th>\n",
       "      <td>63042</td>\n",
       "      <td>21874</td>\n",
       "      <td>84916</td>\n",
       "      <td>0.742404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t9</th>\n",
       "      <td>1879820</td>\n",
       "      <td>94867</td>\n",
       "      <td>1974687</td>\n",
       "      <td>0.951958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>22217</td>\n",
       "      <td>45328</td>\n",
       "      <td>67545</td>\n",
       "      <td>0.328921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11</th>\n",
       "      <td>1012865</td>\n",
       "      <td>52312</td>\n",
       "      <td>1065177</td>\n",
       "      <td>0.950889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t12</th>\n",
       "      <td>52395</td>\n",
       "      <td>12275</td>\n",
       "      <td>64670</td>\n",
       "      <td>0.810190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t13</th>\n",
       "      <td>28600</td>\n",
       "      <td>12294</td>\n",
       "      <td>40894</td>\n",
       "      <td>0.699369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t14</th>\n",
       "      <td>36737</td>\n",
       "      <td>12455</td>\n",
       "      <td>49192</td>\n",
       "      <td>0.746808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t15</th>\n",
       "      <td>25720</td>\n",
       "      <td>12664</td>\n",
       "      <td>38384</td>\n",
       "      <td>0.670071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t16</th>\n",
       "      <td>8837</td>\n",
       "      <td>2852</td>\n",
       "      <td>11689</td>\n",
       "      <td>0.756010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           +      -    count      p(+)\n",
       "t1   1308071  18558  1326629  0.986011\n",
       "t2     26717  31654    58371  0.457710\n",
       "t3   1302381  25752  1328133  0.980610\n",
       "t4     33647   5131    38778  0.867683\n",
       "t5     49359  82704   132063  0.373753\n",
       "t6      7582  13710    21292  0.356096\n",
       "t7     21420  67587    89007  0.240655\n",
       "t8     63042  21874    84916  0.742404\n",
       "t9   1879820  94867  1974687  0.951958\n",
       "t10    22217  45328    67545  0.328921\n",
       "t11  1012865  52312  1065177  0.950889\n",
       "t12    52395  12275    64670  0.810190\n",
       "t13    28600  12294    40894  0.699369\n",
       "t14    36737  12455    49192  0.746808\n",
       "t15    25720  12664    38384  0.670071\n",
       "t16     8837   2852    11689  0.756010"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafr = c_link_census_epinions\n",
    "datafr['count'] = datafr['+'] + datafr['-']\n",
    "datafr['p(+)'] = datafr['+'] / datafr['count']\n",
    "datafr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "      <th>generative</th>\n",
       "      <th>receptive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1308071</td>\n",
       "      <td>18558</td>\n",
       "      <td>1326629</td>\n",
       "      <td>0.986011</td>\n",
       "      <td>111321.119852</td>\n",
       "      <td>117893.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>26717</td>\n",
       "      <td>31654</td>\n",
       "      <td>58371</td>\n",
       "      <td>0.457710</td>\n",
       "      <td>15729.166791</td>\n",
       "      <td>15039.086481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>1302381</td>\n",
       "      <td>25752</td>\n",
       "      <td>1328133</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>97317.230153</td>\n",
       "      <td>103410.663906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>33647</td>\n",
       "      <td>5131</td>\n",
       "      <td>38778</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>10812.877387</td>\n",
       "      <td>11945.291535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>49359</td>\n",
       "      <td>82704</td>\n",
       "      <td>132063</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>12637.912432</td>\n",
       "      <td>21845.810968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6</th>\n",
       "      <td>7582</td>\n",
       "      <td>13710</td>\n",
       "      <td>21292</td>\n",
       "      <td>0.356096</td>\n",
       "      <td>3798.576457</td>\n",
       "      <td>6545.755823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t7</th>\n",
       "      <td>21420</td>\n",
       "      <td>67587</td>\n",
       "      <td>89007</td>\n",
       "      <td>0.240655</td>\n",
       "      <td>7864.566209</td>\n",
       "      <td>14372.535243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t8</th>\n",
       "      <td>63042</td>\n",
       "      <td>21874</td>\n",
       "      <td>84916</td>\n",
       "      <td>0.742404</td>\n",
       "      <td>10262.996304</td>\n",
       "      <td>16267.418979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t9</th>\n",
       "      <td>1879820</td>\n",
       "      <td>94867</td>\n",
       "      <td>1974687</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>122365.296161</td>\n",
       "      <td>133796.271486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>22217</td>\n",
       "      <td>45328</td>\n",
       "      <td>67545</td>\n",
       "      <td>0.328921</td>\n",
       "      <td>15190.799857</td>\n",
       "      <td>15501.347066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11</th>\n",
       "      <td>1012865</td>\n",
       "      <td>52312</td>\n",
       "      <td>1065177</td>\n",
       "      <td>0.950889</td>\n",
       "      <td>85920.121738</td>\n",
       "      <td>94575.254823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t12</th>\n",
       "      <td>52395</td>\n",
       "      <td>12275</td>\n",
       "      <td>64670</td>\n",
       "      <td>0.810190</td>\n",
       "      <td>13631.572367</td>\n",
       "      <td>16912.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t13</th>\n",
       "      <td>28600</td>\n",
       "      <td>12294</td>\n",
       "      <td>40894</td>\n",
       "      <td>0.699369</td>\n",
       "      <td>12578.837635</td>\n",
       "      <td>16912.793199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t14</th>\n",
       "      <td>36737</td>\n",
       "      <td>12455</td>\n",
       "      <td>49192</td>\n",
       "      <td>0.746808</td>\n",
       "      <td>19744.507379</td>\n",
       "      <td>22969.579829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t15</th>\n",
       "      <td>25720</td>\n",
       "      <td>12664</td>\n",
       "      <td>38384</td>\n",
       "      <td>0.670071</td>\n",
       "      <td>11213.456565</td>\n",
       "      <td>14794.611280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t16</th>\n",
       "      <td>8837</td>\n",
       "      <td>2852</td>\n",
       "      <td>11689</td>\n",
       "      <td>0.756010</td>\n",
       "      <td>4224.863777</td>\n",
       "      <td>5820.035169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           +      -    count      p(+)     generative      receptive\n",
       "t1   1308071  18558  1326629  0.986011  111321.119852  117893.774900\n",
       "t2     26717  31654    58371  0.457710   15729.166791   15039.086481\n",
       "t3   1302381  25752  1328133  0.980610   97317.230153  103410.663906\n",
       "t4     33647   5131    38778  0.867683   10812.877387   11945.291535\n",
       "t5     49359  82704   132063  0.373753   12637.912432   21845.810968\n",
       "t6      7582  13710    21292  0.356096    3798.576457    6545.755823\n",
       "t7     21420  67587    89007  0.240655    7864.566209   14372.535243\n",
       "t8     63042  21874    84916  0.742404   10262.996304   16267.418979\n",
       "t9   1879820  94867  1974687  0.951958  122365.296161  133796.271486\n",
       "t10    22217  45328    67545  0.328921   15190.799857   15501.347066\n",
       "t11  1012865  52312  1065177  0.950889   85920.121738   94575.254823\n",
       "t12    52395  12275    64670  0.810190   13631.572367   16912.914894\n",
       "t13    28600  12294    40894  0.699369   12578.837635   16912.793199\n",
       "t14    36737  12455    49192  0.746808   19744.507379   22969.579829\n",
       "t15    25720  12664    38384  0.670071   11213.456565   14794.611280\n",
       "t16     8837   2852    11689  0.756010    4224.863777    5820.035169"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafr = pd.concat([datafr, baselines], axis=1)\n",
    "datafr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr['s_g'] = datafr['count']*datafr['p(+)'] - datafr['generative']\n",
    "datafr['s_g'] = datafr['s_g'] / np.sqrt(datafr['generative'] * (1 - (datafr['generative']/datafr['count'])))\n",
    "datafr['s_g'] = round(datafr['s_g'], 1)\n",
    "\n",
    "datafr['s_r'] = datafr['count']*datafr['p(+)'] - datafr['receptive']\n",
    "datafr['s_r'] = datafr['s_r'] / np.sqrt(datafr['receptive'] * (1 - (datafr['receptive']/datafr['count'])))\n",
    "datafr['s_r'] = round(datafr['s_r'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_B_g = [1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1]\n",
    "pred_B_r = [1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1]\n",
    "pred_S_g = [1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1]\n",
    "pred_S_r = [1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1]\n",
    "\n",
    "datafr['pred_B_g'] = pred_B_g\n",
    "datafr['pred_B_r'] = pred_B_r\n",
    "datafr['pred_S_g'] = pred_S_g\n",
    "datafr['pred_S_r'] = pred_S_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr['B_g'] = datafr['pred_B_g'] * datafr['s_g'] > 0\n",
    "datafr['B_r'] = datafr['pred_B_r'] * datafr['s_r'] > 0\n",
    "datafr['S_g'] = datafr['pred_S_g'] * datafr['s_g'] > 0\n",
    "datafr['S_r'] = datafr['pred_S_r'] * datafr['s_r'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = datafr[['count', 'p(+)', 's_g', 's_r', 'B_g', 'B_r', 'S_g', 'S_r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "      <th>s_g</th>\n",
       "      <th>s_r</th>\n",
       "      <th>B_g</th>\n",
       "      <th>B_r</th>\n",
       "      <th>S_g</th>\n",
       "      <th>S_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>1326629</td>\n",
       "      <td>0.986011</td>\n",
       "      <td>3747.5</td>\n",
       "      <td>3631.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>58371</td>\n",
       "      <td>0.457710</td>\n",
       "      <td>102.5</td>\n",
       "      <td>110.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>1328133</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>4012.7</td>\n",
       "      <td>3882.6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t4</th>\n",
       "      <td>38778</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>258.6</td>\n",
       "      <td>238.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>132063</td>\n",
       "      <td>0.373753</td>\n",
       "      <td>343.5</td>\n",
       "      <td>203.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6</th>\n",
       "      <td>21292</td>\n",
       "      <td>0.356096</td>\n",
       "      <td>67.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t7</th>\n",
       "      <td>89007</td>\n",
       "      <td>0.240655</td>\n",
       "      <td>160.1</td>\n",
       "      <td>64.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t8</th>\n",
       "      <td>84916</td>\n",
       "      <td>0.742404</td>\n",
       "      <td>555.6</td>\n",
       "      <td>407.9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t9</th>\n",
       "      <td>1974687</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>5187.4</td>\n",
       "      <td>4943.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t10</th>\n",
       "      <td>67545</td>\n",
       "      <td>0.328921</td>\n",
       "      <td>64.8</td>\n",
       "      <td>61.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11</th>\n",
       "      <td>1065177</td>\n",
       "      <td>0.950889</td>\n",
       "      <td>3298.1</td>\n",
       "      <td>3128.1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t12</th>\n",
       "      <td>64670</td>\n",
       "      <td>0.810190</td>\n",
       "      <td>373.7</td>\n",
       "      <td>317.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t13</th>\n",
       "      <td>40894</td>\n",
       "      <td>0.699369</td>\n",
       "      <td>171.7</td>\n",
       "      <td>117.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t14</th>\n",
       "      <td>49192</td>\n",
       "      <td>0.746808</td>\n",
       "      <td>156.3</td>\n",
       "      <td>124.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t15</th>\n",
       "      <td>38384</td>\n",
       "      <td>0.670071</td>\n",
       "      <td>162.8</td>\n",
       "      <td>114.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t16</th>\n",
       "      <td>11689</td>\n",
       "      <td>0.756010</td>\n",
       "      <td>88.8</td>\n",
       "      <td>55.8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count      p(+)     s_g     s_r    B_g    B_r    S_g    S_r\n",
       "t1   1326629  0.986011  3747.5  3631.4   True   True   True   True\n",
       "t2     58371  0.457710   102.5   110.5  False  False  False   True\n",
       "t3   1328133  0.980610  4012.7  3882.6   True   True  False   True\n",
       "t4     38778  0.867683   258.6   238.7  False  False   True   True\n",
       "t5    132063  0.373753   343.5   203.8  False  False   True  False\n",
       "t6     21292  0.356096    67.7    15.4   True   True  False  False\n",
       "t7     89007  0.240655   160.1    64.2  False  False  False  False\n",
       "t8     84916  0.742404   555.6   407.9   True   True   True  False\n",
       "t9   1974687  0.951958  5187.4  4943.8   True   True   True  False\n",
       "t10    67545  0.328921    64.8    61.4  False  False  False  False\n",
       "t11  1065177  0.950889  3298.1  3128.1   True   True  False  False\n",
       "t12    64670  0.810190   373.7   317.5  False  False   True  False\n",
       "t13    40894  0.699369   171.7   117.4  False  False   True   True\n",
       "t14    49192  0.746808   156.3   124.4   True   True  False   True\n",
       "t15    38384  0.670071   162.8   114.6  False  False  False   True\n",
       "t16    11689  0.756010    88.8    55.8   True   True   True   True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_index = pd.Index([f't{i}' for i in range(1, 17)])\n",
    "\n",
    "# datafr.set_index(new_index, inplace=True, drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
